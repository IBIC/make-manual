\chapter{Running \maken{} in Parallel}
\label{chap:parallel}

Although it is very powerful to be able to use makefiles to launch jobs in parallel, some care needs to be taken when writing the makefile, as with any parallel program, to ensure that simultaneously running jobs do not conflict with each other. In general, it is good form to follow these rules for all makefiles, because it seems highly likely that if you ignore them, there will come a deadline, and you will think to yourself ``I have eight cores and only a few days'' and you will run \maken{} in parallel, and all of your results will be subtly corrupted due to your lack of forethought, something you won't discover until you only have a few hours left. This is the way of computers.

\section{Guidelines for Writing Parallelizable Makefiles}

There are a few key things to remember when setting running \maken{} in parallel.

\subsection{Each line in a recipe is, by default, executed in its own shell}

This means that any variables you set in one line won't be ``remembered'' by the next line, and so on. The best thing to do is to put all lines of a recipe on the same line, by ending each of them with a semicolon and a backslash (\texttt{;\textbackslash}). Similarly, when debugging a recipe in a parallel makefile gone wrong, look first for a situation where you have forgotten to put all lines of a recipe on the same line. For example, the recipe shown in \autoref{make:fail} will not work as intended, not matter what, because the first line of this recipe is not remembered by the second, and \texttt{brain.volume.txt} will be empty.
\begin{make}{A non-functional multi-line makefile}{make:fail}
	set foo=\`{}fslmaths brain.nii.gz -V | awk '{print \$\$2}'\`{} \\
	cat \$\$foo > brain.volume.txt
\end{make}


Instead, write the script as shown in \autoref{make:failfix}. Note the \texttt{;\textbackslash} in red connects the two lines.
\begin{make}{A now-functional multi-line makefile}{make:failfix}
	set foo=\`{}fslmaths brain.nii.gz -V | awk '{print \$\$2}'\`{} \texttt{{\color{red} ;\textbackslash}} \\
	cat \$\$foo > brain.volume.txt
\end{make}

You can also use \texttt{\&\&}, a \texttt{bash} operator that executes the next command only if the previous command was successful\footnote{In other words, has exited with an exit status (\texttt{\$?}) of ``0.''}. For example:
\begin{make}{A multi-line makefile using ``\texttt{\&\&\textbackslash}''}{make:ampersandfix}
	set foo=\`{}fslmaths brain.nii.gz -V | awk '{print \$\$2}'\`{} \&\&\textbackslash\\
	cat \$\$foo > brain.volume.txt
\end{make}

In this instance, \texttt{bash} will not attempt to \texttt{cat} the file if \texttt{fslmaths} or \texttt{awk} failed.

\subsection{Filenames must be unique}

It is very tempting to do something like the following, or the previous example, as  you would while interactively using a shell script.
\begin{make}{How not to name files}{make:badfoo}
	some_program > foo.out ;\textbackslash \\
	do something \dd now \dd with foo.out
\end{make}

This will work great sequentially; first \texttt{foo.out} is created and then it is used. You have attended to rule \mypound 1 and the commands will be executed together in one shell. But consider what happens when four processors run this recipe independently, in the same directory. Whichever recipe completes first will overwrite \texttt{foo.out}. This could happen at any time, so it is entirely possible that process A writes \texttt{foo.out} just in time for process B to use it. Meanwhile, process C can come along and rewrite it again. You see the point. The best way to avoid this problem, no matter how the makefile is used, is to create temporary files (like \texttt{foo.out}) that include a unique identifier, such as a subject identifier. For longitudinal analysis we play it safe and always use a timepoint identifier as well. Thus, whether you conduct your analysis using one subdirectory per subject or in a single directory for the entire analysis, you can take the recipe you have written and use it without modification. Another approach is to create unique temporary names using the \texttt{mktemp} program and delete them when you are finished. 

Many neuroimaging software packages use the convention that files within a subject-specific directory that contains a subject identifier can have the same names. In that case, just go with it: They have done that in part to avoid this confusion while running the software in parallel on a shared filesystem.

\subsection{Separate time-consuming tasks}

Try to separate expensive tasks into seperate recipes. Suppose you have two time-consuming steps: \texttt{run_a} and \texttt{run_b}. \texttt{run_a} takes half an hour to generate \texttt{a.out} and \texttt{run_b} takes an hour to generate \texttt{b.out}. Additionally, \texttt{run_a} must complete before the other can begin. Examine the rule in \autoref{make:twolong}.
\begin{make}{The wrong way to run two long tasks}{make:twolong}
	\maker{a.out b.out}{b.in} \\
	\tab run_a ;\textbackslash \\
	\tab run_b
\end{make}

This works, but suppose another task only needs \texttt{a.out}, and doesn't depend at all on \texttt{b.out}. You would spend a lot of extra time generating \texttt{b.out}, especially if this was a batch job. So it is better to write the rule in two separate lines, as in \autoref{make:twoshort}.

\begin{make}{The right way to run two long tasks}{make:twoshort}
	\maker{a.out}{b.in} \\
	\tab run a \\
	
	\maker{b.out}{a.out} \\
	\tab run_b
\end{make}

\section{Executing in Parallel}
\label{sec:gridengine}
\subsection{Using multiple cores}

Most modern computers have multiple processing elements (cores). You can use these to execute multiple jobs simultaneously by passing the \texttt{-j} option to \maken.

First you need to know the number of cores on your machine. The command \texttt{nproc} might work, or you can ask your system administrator.

You have to be careful not to start a lot more jobs than you have cores, other wise the performance of all the jobs will suffer. Let us assume there are four cores available. Pass the number of jobs to \maken. 
\bashcmd{make -j 4}

Now you will execute the four cores simultaneously. This will work well if no one else is using your machine to run jobs. 

Recall that \maken{} will die when it obtains an error. When running jobs in parallel, \maken{} can encounter an error that much faster. If one job dies, all the rest will be stopped. This is rarely the behavior you want, because typically each job is independent of the others. To tell make not to give up when the going gets tough, use the \texttt{-k} (keep going!)flag.
\bashcmd{make -j 4 -k}

\section{Using the grid engine}

Four cores (or even eight or 12 or 24) is nice, but a cluster is even nicer. A cluster gangs together several multi-core machines to act like one. Our cluster environment is the Sun Grid Engine (SGE) which is a batch queuing system. This software layer allows you to submit jobs, queue them up, and farm them out to one of the many machines in the cluster.
\mymarginnote{!}{You can submit jobs from any machine in a grid engine. In IBIC, \texttt{broca} and \texttt{pons} are the easiest to type.}

\subsection{Setting \texttt{FSLPARALLEL} for FSL jobs}

There are two ways to use \maken{} to run jobs in parallel on the SGE. The first is to use the scripts for parallelism that are built in to FSL. In our configuration, all you need to do is set the environment variable \texttt{FSLPARALLEL} from your shell as follows:
\bashcmd{export FSLPARALLEL=true}

This must be done before running \maken! Then, you run your makefile as you would on a single machine, on a machine that is allowed to submit jobs to the SGE (check with your system administrator to find out what this is). What will happen is that the FSL tools will see that this flag is set, and use the script \texttt{fsl_sub} to break up the jobs and submit them to the SGE. You do not need to set the \texttt{-j} flag as above, because FSL will control its own job submission and scheduling. 

Note that this trick will only work if you are using primarily FSL tools that are written to be parallel. What happens if you want to use something like \texttt{bet} on 900 brains (which is not parallelized), or other tools that are not from FSL?

\subsection{Using \texttt{qmake}}

By using \texttt{qmake}, a program that interacts with the SGE, you can automatically parallelize jobs that are started by a makefile. This is a useful way to structure your workflows, because you can run the same neuroimaging code on a single core, a multicore, and the SGE simply by changing your command line. You may need to discuss specifics of environment variables that need to be set to run \texttt{qmake} with your system administrator. If you are using \maken{} in parallel, you also will probably want to turn off \texttt{FSLPARALLEL} if you have enabled it by default.

There are two ways that you can execute qmake, giving you a lot of flexibility. The first is by submitting jobs dynamically, so that each one goes into the job queue just like a mini shell script. To do this, type
\bashcmd{qmake -cwd -V \dd{} -j 20 all}

\textbf{The flags that appear before the ``\dd{}'' are flags to \texttt{qmake},} and control grid engine parameters. The \texttt{-cwd} flag means to start grid engine jobs from the current directory (useful!) and \texttt{-V} tells it to pass all your environment variables along. If you forget the \texttt{-V}, we promise you that very bad things will happen. For example, FSL will crash because it can't find its shared libraries. Many programs will ``not be found'' because your path is not set correctly. Your jobs will crash, and that earthquake will kill all of us.

\textbf{On the opposite side of the ``\dd{}'' are flags to \maken.} By default, just like normal \maken, this will start exactly one job at a time. This is not very useful! You probably want to specify how much parallelism you want by using the -j flag to make (how many jobs to start at any one time). The above example runs 20 jobs simultaneously. The last argument, \texttt{all}, is a target for \maken{} that is dependent upon the particular makefile used.

One drawback of executing jobs dynamically is that make might never get enough computer resources to finish. For this reason, there is also a parallel environment for \maken{} that reserves some number of processors for the \maken{} process and then manages those itself. You can specify your needs for this environment by typing
\bashcmd{qmake -cwd -V -pe make 1-10 \dd{} freesurfer}

This command uses the \texttt{-pe} to specify the parallel environment called \texttt{make} and reserves 10 nodes in this environment. The argument to \maken{} is \texttt{freesurfer} in this example. Note that we do not use this environment in IBIC.

\subsection{How long will everything take?}

A good thing to do is to estimate how long your entire job will take by running \maken{} on a single subject and measuring the ``wall clock'' time, or the time that it takes between when you start running it and when it finishes. If you will be going home for the night, add a command to print the system date (\texttt{date}) as the last line in the recipe, or look at the timestamp of the last file created. Suppose one subject takes 12 hours. Probably other subjects will take, on average, the same amount of time. So you multiply the number of subjects by 12 hours, and divide by 24 to get days. For 100 subjects, this job would take 50 days. This calculation tells you that it would be a long time to wait for your results on your four-core workstation (and in the meantime, it would be hard to do much else). 

Suppose you have a cluster of 75 processors, and 100 subjects. If you can use the entire cluster, you can divide the number of subjects by processors and round up. This gives you two. If you multiply this by your average job time, you find that you can complete this job on the cluster in one day. If you think about this, you see that if you had 100 processors, you could finish in half the time (12 hours) because you would not have to wait for the last 25 jobs to finish.

\subsection{Consideration of memory}

Processing power is not the only resource to consider when running jobs in parallel. Some programs (for example, \texttt{bbregister} in our environment) require a lot of memory. This means that attempts to start more jobs than the available memory can support will cause the jobs to fail. A good thing to do is to look at the system monitor while you are running a single job, and determine what percentage of the memory is used by the program (find a computer that only you are using, start the monitor before you begin the job, and look at how much additional memory is used, at a maximum, while it runs). If you multiply this percentage by the number of cores and find that you will run out of memory, do not submit the maximum number of jobs. Submit only as many as your available resources will support.

\section{Troubleshooting \maken}

One flaw of \maken{} (and indeed, many UNIX and neuroimaging programs and just life in general) is that when things do not go as expected, it is difficult to find out why. These are some hints and tricks to help you to troubleshoot when things go wrong.

\subsection{Find out what \maken{} is trying to do}

Start from scratch, remove the files you are trying to create, then execute \maken{} with the \texttt{-n} flag.
\bashcmd{make -n all}

You can also place the flag at the end of the command. This way, it is easy to hit $\uparrow$ and delete \texttt{-n} without having to muck about arrowing over to the flag placed at the beginning of the command. By doing this you could save seconds a day!
\bashcmd{make all -n}

The \texttt{-n} flag shows what commands will be executed without executing them. This is very handy for debugging problems, as it tells you what make is actually programmed to do. Remember, computers do exactly what you tell them.

\subsection{Use the trace option in \maken{} 4.1}
Debugging is such an issue that the latest version of GNU \maken{}, version 4.1, has tracing functionality to show you what is going on. Even if your system does not have this installed, you can download it and run it with the \texttt{--trace} option. Note that there are some subtle differences between \maken{} versions. For a thorough desciption of version differences and more debugging options, see \citation{GnuMakeBook}.

\subsection{Check for line continuation}

Ensure that you have connected subsequent lines of a recipe with a semicolon and a backslash (\texttt{;\textbackslash}). If you don't do this, each line will be run in a separate shell, and variables from one will not be readable in the other.

\subsection{No rule to make target!}

Suppose you write a makefile and include in it what you think should be a rule to create a specific file (say, \texttt{data_FA.nii.gz}). However, when you type \maken, you get the following message: \\
\texttt{make: *** No rule to make target \`{}data_FA.nii.gz', needed by \`{}all'}

This can be rather frustrating. There are multiple ways this error message could be generated. We recommend the following steps to diagnose your makefile.

\begin{easylist}[enumerate]
	& Read the error message. \\ Seriously. It is tempting to try to read a program's mind, but inevitably this fails. Mostly because they don't have minds. In the error above, the key aspects of the error above are as follows:
	&& The error comes from \maken, as you can see by the fact that the line starts with \texttt{make:}. It is also possible that your Makefile fails because a program that you called within it fails (and you either did not specify the \texttt{-k} flag to keep going, or there is nothing left to do).
	&& \maken{} claims that there is ``no rule'' to make the target ``\texttt{data_FA.nii.gz}.'' This tells you that \maken{} could not find a target: dependency combination to create this particular target.
	&& \maken{} is trying to create this target to satisfy the target \texttt{all}. This tells you that it was trying to make \texttt{data_FA.nii.gz} because this is a dependency of the target \texttt{all}.
	& If your error is indeed coming from \maken, then try to pinpoint the rule that is failing. \emph{Look} at your makefile and check that the rule looks correct. Do all the dependencies of the rule (the things to the left of the colon) exist? Are they where they should be? Can you read them?
	& If everything looks ok, you are missing something. Rules that expand patterns and that use variables can be tricky to interpret (the same way that you generally like a debugger to look at code). To see what make is really doing with your rules, use the \texttt{-p} flag to print the database and examine the rules. We suggest doing this in conjunction with \texttt{-n} so that you do not actually execute anything.
	& Pattern matching has an odd behavior where, if there is no rule to create a dependency, it will tell you there is no rule to create the target. \\ For example, \autoref{make:pmbehavior} will fail with \\ \texttt{\ldots{} No rule to make target \`{}<subj>_T1_brain.nii.gz' \ldots} \\not \\ \texttt{\ldots{} No rule to make target \`{}foo' \ldots }
	\begin{make}{Pattern-matching error handling}{make:pmbehavior}
		\maker{\%_T1_brain.nii.gz}{\%_T1.nii.gz foo} \\
		\tab bet \$< \$@ 
	\end{make}
\end{easylist}

\subsection{Suspicious continuation in line \mypound{}} % ignore the error this line throws, it's fine.

If you get this error while trying to save a makefile (using \texttt{emacs}, which is smart enough to help you ensure the syntax of your makefile is correct), it means that you probably have a space after the trailing \texttt{;\textbackslash} at the end of the line. No, you can't have indiscriminate whitespace in a makefile!

\subsection{\maken{} keeps rebuilding targets}

A more subtle problem occurs when your makefile works the first time, but it also ``works'' the second time \ldots and the third \ldots and so on. In other words, it keeps rebuilding targets even when they do not ``need'' to be rebuilt. This means that \maken{} examines the dependencies of the target, decides that they are newer than the target (or that the target does not exist) and executes the recipe.

This cycle never stops if, somewhere, a target is specified that is never actually created (and that is not marked as phony). This is easy to do, for example, when trying to execute more complex neuroimaging pipelines (such as those provided by FSL) that create entire directories of files with specific naming conventions. Check that the commands that keep re-executing really create the targets that would indicate that the command has completed. For example, when running \texttt{feat} with a configuration file, the name of the output directory is specified in the configuration file. This must be the same as the target in the Makefile, or it will never be satisfied.

\subsection{\maken{} doesn't rebuild things that it should}

This type of error usually indicates a logical problem in the tree of targets that begins with what you have told make to do. Recall that by default, \maken{} builds the first target that appears in the makefile. If you have included makefiles at the beginning of your file, it might happen that the default target is not actually what you think it is.
