\chapter{Running \maken{} in Context}
\label{chap:context}

\section{File Naming Conventions}
\label{sec:naming}

File naming conventions are also critical for scripting in general, and for Makefiles in particular. \maken{} is specifically designed to turn files with one extension (the extension is the last several characters of the filename) into files with another extension. For example, in \autoref{make:recipe1} we turned a file with an extension ``T1.nii.gz'' into a file with the extension ``T1_skstrip.nii.gz.'' 
\mymarginnote{!}{``\textbf{Extension}'' often refers to the file suffix, e.g., ``.csv,'' but there is no reason it must be limited to a fixed number of characters after a period.}

So we can use naming conventions within a project, and across projects consistently to reuse rules that we write for common operations. In fact, \maken{} has many built-in rules for compiling programs that are absolutely useless to us. But we can write our own rules.

Thus, it is important to decide upon naming conventions. 

\subsection{Subject Identifiers}

The first element of naming conventions is the subject identifier. This is usually the first part of any file name that we might end up using outside of its directory. For example, when processing resting state data, the final cleaned data begins with the subject identifier, allowing us to dump all those files into a new directory for subsequent analysis with another program, without having to rename them or risk overwriting other subject files. Some features (by no means exhaustive) that may be useful for subject identifiers are:

\begin{easylist}[enumerate]
	& \textbf{They should contain some indicator of which project the subjects belong to.} \\
	This is particularly important if you work on multiple projects, or if you may be pooling data from multiple studies. Typically choose a multi-letter code that is the prefix to the subject ID.
	& \textbf{If applicable, it should contain some indicator of treatment group that the subject belongs to.} \\
	It is helpful to indicate in the subject ID (usually with another letter or digit code) whether the subject is part of a treatment group or a control.
	& \textbf{They should be short.} \\
	Short names are easier to type and to remember, and make it easier to work with lists of directories that are named according to the subject id.
	& \textbf{They should be the same length.} \\
	This is not necessary but helpful for pattern matching using wildcards in a variety of contexts within \maken{} and without.
	& \textbf{They should sort reasonably in UNIX.} \\
	Many utilities ultimately require a list of filenames, which is easy to generate using wildcards and the treatment group code if the subject ID sort order is reasonable. The classic problem is to name subjects S1 \ldots S10, S11 -- the subjects will not be in numeric order without zero-padding to the subject numbers.
	& \textbf{They should be easy to type.} \\
	\bashn{} has many tricks to help you avoid typing, but when you have to type, the farther you have to move the longer it takes.
	& \textbf{They should be easy to remember for short periods of time.} \\
	My attention span is very short when doing repetitive tasks; subject IDs that are nine-digit random numbers are harder to remember than subject IDs that are four letter random sequences. 
	& \textbf{They should be easy to divide into groups using patterns.} \\
	My favorite set of subject IDs were randomly generated four letter sequences, making it easy to divide the subjects into groups of just about any size using the first letters and wildcards. This makes it very easy to test something on a subset of subjects. 
	& \textbf{They should be consistently used in all data sets within the project.} \\
	If the subject identifier is ``RC4101'' in a directory, it should not be ``RC4-101'' in the corresponding Redcap database and ``101'' in the neuropsychological data -- it is easier if everyone can decide upon one form of name.
\end{easylist}

\subsection{Filenames}

File naming conventions begin with converted raw data (nifti files derived from the original DICOMs, for example), and continue on for each level of processing. We find it helpful to give these files specific names and then to perform subject-specific processing within the subject/session directory. The filenames for a recent active project are shown in \autoref{table:filenames}, where the subject ID is ``RPI001.''

\rowcolors*{2}{gray!50}{white} 	% alternating row coloing, starting on row 2 (ignore header)
\def\arraystretch{1.2}	% with all the caps, this table gets a little crammed. 
\begin{figure}[h!]
	\begin{tabularx}{\linewidth}{ >\ttfamily l X } % >\ttfamily applies monospaced font to column 1
											% column 1 expands, and forces 2 to shrink and wrap
		\rowcolor{gray!75}
		\normalfont\textbf{Filename} 		& \textbf{Description} 	\\ \hline
		RPI001_T1_brain.nii.gz	& Skull stripped T1 MPRAGE image 	\\  
		RPI001_T1.nii.gz		& T1 MPRAGE image 					\\  
		RPI001_read.nii.gz		& Reading task scan 				\\  
		RPI001_read_rest.nii.gz	& Resting state scan for reading session	\\ 
		RPI001_read_fMRIb0_phase.nii.gz	& RPI001_read_fMRIb0_mag.nii.gz		\\  
		RPI001_read_fMRIb0_mag_brain.nii.gz & Reading task B0map phase image, magnitude image and brain overlaying over magnitude image	\\  
		RPI001_write.nii.gz		& Writing task scan 				\\  
		RPI001_write_rest.nii.gz	& Resting state scan for writing session	\\  
		RPI001_write_fMRIb0_phase.nii.gz	& RPI001_write_fMRIb0_mag.nii.gz	\\  
		RPI001_write_fMRIb0_mag_brain.nii.gz	& Writing task B0map phase image, magnitude image and skull stripped magnitude image	\\ 
		RPI001_DTI.nii.gz		& DTI image 						\\ 
		bvecs.txt				& bvalues and bvectors for  DTI processing 	\\  \hline
		%		bvals.txt & \\ \hline
	\end{tabularx}
	\caption{Example of good file naming conventions}
	\label{table:filenames}
\end{figure}

The specific file names chosen are not as important as consistency in the use of extensions and names, and documentation of what these files are and how they were processed. The more you can keep things the same between projects, the more you will be able to reuse from one study to another with minimal changes. 

\section{Directory Structure}
\label{sec:dir}

Typically, we create a directory for each project. Within that project directory is storage for scripts, masks, data files from other sources (e.g., cognitive or neuropsychological data) and subject neuroimaging data. Subjects may have different timepoints or occasions of imaging data, as well as physiological data and task-related behavioral data.
An example hierarchy (for project Udall) is shown in \autoref{figure:udalldir}.

\begin{center}
	\begin{figure}[h!]
		\dirtree{%
			.1 /project_space/Udall.
			.2 bin\DTcomment{Holds scripts written for this project}.
			.3 R\DTcomment{Holds R scripts}.
			.3 tcl\DTcomment{Holds tcl scripts}.
			.2 data\DTcomment{Other sources of data for all subjects}.
			.2 lib\DTcomment{Holds things that are used by many scripts and analyses}.
			.3 makefiles\DTcomment{Makefiles for this project}.
			.4 networkROIs\DTcomment{A set of ROI masks for fMRI analysis}.
			.4 tractographyMasks\DTcomment{A set of masks for tractography analysis}.
			.2 freesurfer\DTcomment{Freesurfer (cortical thickness) runs}.
			.2 tbss\DTcomment{Group-level Tract-Based Spatial Statistics}.
			.2 subjects\DTcomment{All subject data collected in neuroimaging sessions}.
			.3 SUBJECT\DTcomment{A specific subject}.
			.4 session1\DTcomment{Difference subject sessions}.
			.4 session2.
			.4 session3.
			.5 behavioral\DTcomment{Subject behavioral (e.g., task) data}.
			.5 Dicoms\DTcomment{Original dicoms}.
			.5 Parrecs\DTcomment{PAR/REC files, the native Philips scanner format}.
			.5 physio\DTcomment{Physiological data}.
			.5 xfm_dir\DTcomment{Registration files}.
			.3 session3/SUBJECT\DTcomment{Symbolic link to the subject/session3 directories}.
			.3 incoming\DTcomment{Zip files with subject data from the scanner.}.
		}
		\caption{An example of a project directory.}
		\label{figure:udalldir}
	\end{figure}
\end{center}

This directory is typically protected so that only members of the project who are permitted by the Institutional Review Board to access the data may \texttt{cd} into the directory, using a specific group related to the project. The sticky bit is set on the project directory and the file permissions are set by default to permit group read, write, and execute permission for each individual so that files people create within the directory substructure are accessible by others in the project. 

\mymarginnote{?}{The \textbf{sticky bit} prevents users from deleting files created by other users.}

The structure is set up for a longitudinal project, where each subject is imaged at separate time points (sessions). All subject data is stored under the directory subjects (under subdirectories corresponding to each session). However, since often it is convenient to conduct analyses on a single time point, we create a convenience directory at the top level (e.g., session3) which has symbolic links to all of the subjects' session 3 data. This can make it easier to perform subject-specific processing (see \autoref{sec:analysisdir}).

Notice that in the project directory, we also keep scripts that we write to process the data, other data files, and miscellaneous support files for workflow (in the \texttt{lib/} subdirectory). Your naming conventions may differ and there may be more categories than we have, but it is important to decide upon some structure that everyone agrees upon for the project.

We find it useful to locate the results of some subject-specific processing (e.g. co-registration of files, subject-level DTI processing, subject-level task fMRI processing) in the subject/session directories. However, other types of analyses are more conveniently performed in directories (e.g. \texttt{freesurfer/}, \texttt{tbss/}) that are stored at the top level of the project.

Data files that are collected from non-neuroimaging sources are usually kept in text (tab or comma-separated) form in the \texttt{data/} directory so that scripts can find and use them (e.g., to use the subject age or some cognitive variable as a regressor in an analysis).

Finally, note that we have a directory labeled incoming. This is a scratch directory (it could be a symbolic link to a scratch drive) for placing zip files that come from the scanner, that contain the dicoms for the scan, the Philips-specific PAR/REC files, the physiological data logged (used to correct functional MRI data for heart rate and respiration-related signal) and data from scanner tasks (e.g., EPRIME files).

\section{Setting up an Analysis Directory}
\label{sec:analysisdir}

We have described, up until this point, little examples of makefiles that process subjects within a single directory. However, real studies include many subjects and many analyses; each analysis often produces hundreds of files per subject. Often, several researchers are trying to conduct different analyses on the same data set at the same time.

% add reference to incoming makefile
For these reasons, we use a collection of makefiles to manage a project. This section describes this basic recipe (which is a little complicated). Typically the steps involving creating subject directories and links are done by a script or an ``incoming'' makefile at the time that the subject data appears from the scanner. Better, if you use an archival system that you can write programs to access (for example, XNAT) a script can create all the links and name files nicely for you.

This relies on the concept of a ``symbolic link.'' This is a file that points to another file or directory. If you remove the link, you will not remove the thing that it points to. However, if you remove the target of the link, the link won't work any more.

To create a symlink, use the \texttt{ln} command.
\bashcmd{ln -s target linkname}

\texttt{target} is the file you're linking to, and \texttt{linkname} is the name of the new symlink.

\subsection{Defining the basic directory strucutre}
See \autoref{sec:dir} for more information on this step, which is important. Let us assume the project home (\texttt{PROJHOME}) is called \texttt{/project_space/Udall/}. There are three scans per individual. Let us also assume there are two subjects: RC4101 and RC4103. These are the directories that need to be in place. Note we organize the actual files by subject ID and scan session. However, to make processing at each cross-sectional point easier, we create directories with symbolic links to the correct subject/session directories. This flexibility helps in many ways to make cross-sectional and longitudinal analyses easier.

All simple subject-specific processing is well-organized within the subject/session directories (for example, skull-stripping, possibly first level feat, dti analysis, co-registrations). We normally run FreeSurfer in a separate directory, because it likes to put directories in a single place. Analyses that combine data across subjects or timepoints (e.g. TBSS) best go in separate directories.

\autoref{figure:longdirtree} shows an example directory for a longitudinal study.

\begin{center}
	\begin{figure}
		\dirtree{%
			.1 /project_space/Udall.
			.2 subjects\DTcomment{All subject data collected in neuroimaging sessions}.
			.3 RC4101.
			.4 session1.\DTcomment{Subject-level processing happens here.}.
			.4 session2.
			.4 session3.
			.3 RC4103.
			.4 session1.
			.4 session2.
			.4 session3.
			.2 session1/RC4103\DTcomment{Symbolic link to subjects/RC4103/session1.}.
			.2 session2/RC4101\DTcomment{Symbolic link to subjects/RC4101/session2.}.
			.2 session2/RC4103\DTcomment{and so on.}.
			.2 session3/RC4101.
			.2 session3/RC4103.
		}
	\caption{A longitudinal analysis directory.}
	\end{figure}
	\label{figure:longdirtree}
\end{center}

\subsection{Create the session-level makefiles}
We will do all the subject-level processing from the \texttt{PROJHOME/sessionN/} directories. You will need to create a Makefile in \texttt{PROJHOME/sesion1}, \texttt{PROJHOME/sesion2}, and \texttt{PROJHOME/sesion3} whose only purpose is to run \maken{} within all the subject-level directories beneath it. 
\autoref{make:seshlevel} shows an example session-level makefile.

\mymarginnote{?}{\textbf{\#} is the \maken{} comment character.}

\begin{make}{Session-level Makefile}{make:seshlevel}
	\# Top level makefile \\
	\# make recursively all make targets in each subject directory.\\
	
	\# Obtain a list of subject - here all directories of the form RC4 followed by three characters \\
	SUBJECTS=\$(wildcard RC4????) \\
	
	\maker{.PHONY}{all \$(SUBJECTS)} \\
	
	define usage \\
	\tab @echo Usage: \\
	\tab @echo ``make \ldots Makes everything in subdirectories'' \\
	\tab @echo ``\tab Remember to specify TARGET=?'' \\
	\tab @echo Other useful targets: \\
	\tab @echo ``make help \ldots Print this message.'' \\
	endef \\
	
	\maker{all}{\$(SUBJECTS)} \\
	
	\maker{\$(SUBJECTS)}{} \\
	\tab \$(MAKE) --directory=\$@ \$(TARGET)  \\
	
	\maker{help}{}
	\tab \$(usage)
\end{make}

Using the \texttt{@} before a command stops \maken{} from echoing the command before executing it.

\subsection{Creating the common subject-level makefile for each session}
As we described, the session-level makefile only exists to call \maken{} within all the subdirectories (symbolic links) in each session. So, we need to create a makefile within each subdirectory. This would be incredibly redundant! In general, we try to minimize copying of makefile rules where ever possible. We create three files based on a modified version of \autoref{make:seshlevel}:

\ttfamily\selectfont
\begin{easylist}[itemize]
	& PROJHOME/session1/makefile_common.mk
	& PROJHOME/session2/makefile_common.mk
	& PROJHOME/session3/makefile_common.mk
\end{easylist}
\normalfont

Note that \autoref{make:subjlevel} sets a \texttt{SESSION} variable. In the example, it is set to ``2,'' but you will tailor this for each of your own sessions. It also sets a \texttt{SUBJECT} variable by setting the last part of the file path. This is useful for makefiles you write. If everyone agrees on setting these two variables, you can use them in makefiles that are written to be portable across projects.

We include a little test rule here that merely echoes the subject variable. Most of the rules should normally come from makefiles that are established pipelines, that have been tested with this project (\texttt{process_incoming.mk} and \texttt{convert_dicoms.mk}). These are stored in \texttt{PROJHOME/lib/makefiles/} to make them easier to find and share across sessions.

\begin{make}{Subject-level makefile}{make:subjlevel}
	\# This is the project home directory \\	
	PROJHOME=/project_space/Udall \\
	
	\# Name the session Â­CHANGE THIS FOR EACH SESSION \\	
	SESSION=2 \\
		
	\# get subject id \\
	subject=\$(notdir \$(shell pwd)) \\
	
	\# put your own rules here\\
	
	\maker{test}{}	\\
	\tab @echo Testing that we are making \$(subject) \\
	
	\# rules from other libraries \\	
	include \$(PROJHOME)/lib/makefiles/process_incoming.mk \\	
	include \$(PROJHOME)/lib/makefiles/convert_dicoms.mk
\end{make}

\subsection{Creating links to subject-level makefile}
The last step now is to create a symbolic link within each subject directory to the appropriate subject-level makefile. For example, within the directory \texttt{PROJHOME/session2/RC4101/}, we can type
\bashcmd{ln -s /project_space/Udall/subjects/session2/makefile_common.mk Makefile}

\subsection{Running analyses}
Once these steps are completed, you can conduct single-subject processing for each session by changing directory to the correct location and issuing the specific \maken{} command. Here, we illustrate how to make the ``test'' target for all subjects within \texttt{session2/}.

\begin{bash}{Making \texttt{test}}{bash:test}
	cd /project_space/Udall/subjects/session2 \\
	make TARGET=test
\end{bash}

\section{Setting Important Variables}

\maken{} uses variables to control a lot of aspects of its own behavior. We describe only a few here; see the manual for the full list. However, it also allows you to set variables so that you can avoid unnecessary changes to Makefiles when you move them to different projects. This is very important, because after going through the hassle of writing a makefile for an analysis once, we would like to reuse as much of it as possible for subsequent studies. It is reasonable to change the recipes to reflect the most appropriate scientific methods or new versions of software, but it's not fun to have to play with naming conventions, etc. We discuss some of the best practices we have found for using variables to improve portability.

\subsection{Variables that control \maken's Behavior}

\subsubsection{\texttt{SHELL}}
By default the shell used by make recipes is \texttt{/bin/sh}.  This shell is one of many that you can use interactively in Linux or MacOS, but it probably is not what you are using interactively (because it lacks nice editing capabilities and is less usable than other shells). Here, we set the default shell to \texttt{/bin/bash}, the same as what we use interactively, so that we can be sure when we test something at the command line that it will work similarly in a Makefile.

\begin{make}{Setting \texttt{\$(SHELL)}}{make:shell}
	\# Set the default shell \\
	SHELL=/bin/bash \\
	export SHELL
\end{make}

Note that \texttt{SHELL} is accessed \texttt{\$(SHELL)}, as is other \maken{} variable. 

\subsubsection{\texttt{TARGET}}
In the strategy that we outline for organizing makefiles and conducting subject-level analyses, we run \maken{} recursively (i.e., within the subject directories) from the session-level directory. To do this very generally, we call make from the session-level by specifying the TARGET, or what it should ``make'' within the subject directory. You do not need to do this within the subject directory itself. For example:

(in \texttt{subjects/session1})

\bashcmd{make TARGET=convert_dicoms}

(in \texttt{subjects/session1/s001})

\bashcmd{make convert_dicoms}

\subsubsection{\texttt{SUBJECTS}}
We think it makes life easier to set this to the list of subjects in the study (or subjects for whom data has been collected). For example, given our directory structure, when in the top level for a session, the subject identifiers can easily be found with a wildcard on the directory names. The following statement sets the variable \texttt{SUBJECTS} to be all the six-digit files in the current directory (i.e., all the subject directories.) 

\makecmd{SUBJECTS=\$(wildcard [0-9][0-9][0-9][0-9][0-9][0-9])}

\subsubsection{\texttt{subject}}
Often makefiles are intended to process a single subject. In this case, it is useful to set a subject variable to be the subject identifier.

\subsubsection{\texttt{SESSION}}
When subject data is collected at multiple time points, it is useful to set at \texttt{SESSION} variable that can be used to locate the correct subject files. 

\subsection{Other important variables}
Ultimately, when it comes time to publish, it is important to state what version of the different software packages you have used. This means that you need to make it difficult to accidentally run a job with a different version of the software. For example, consider this rule to run \texttt{DTIPrep}, a program for eddy correction, motion correction, and removal of noise from DTI images. % TO DO: cite DTIPrep

\begin{make}{Running DTIPrep in make}{make:dtiprep}
	\maker{dtiprep/\$(subject)_dwi_QCReport.txt}{dtiprep\$(subject)_dwi.nhdr} \\
	\tab DTIPrep \dd DWINrrdFile \$< -p dtiprep/default.xml \dd default \dd check \dd outputFolder dtiprep/ \\
\end{make}

Unless you take preventative measures, the version of \texttt{DTIPrep} that is used depends on the caller's path. So if the version of \texttt{DTIPrep} on one machine is newer than that on another, the results may differ. Alternatively, if my graduate student runs this makefile, and happens to have the newest version fo DTIPrep installed in their \texttt{bin/}, that is the version that will be used.

A practical way to control for this is to specify the location of the program (if that conveys version information). See \autoref{make:dtiv}

\begin{make}{Controlling software version}{make:dtiv}
	DTIPREPHOME=/usr/local/DTIPrep_1.1.1_linux64/DTIPrep \\
	
	\maker{dtiprep/\$(subject)_dwi_QCReport.txt}{dtiprep\$(subject)_dwi.nhdr} \\
	\tab DTIPrep \dd DWINrrdFile \$< -p dtiprep/default.xml \dd default \dd check \dd outputFolder dtiprep/ \\	
\end{make}

What about when the programs are installed in some default location, e.g. \texttt{/usr/local/bin/}, with no version information? In our installation, this occurs frequently when using other workflow scripts that express pipelines more complicated than what might reasonably be put into a makefile.

In the case of simple scripts or statically linked programs, it is fairly easy to copy them into a project-specific bin directory, giving them names that indicate their versions. If you cannot do this, you need to check the version (if the program is kind enough to provide an option that will provide the version) or to check the date that the program was installed, to alert yourself to potential errors. It is useful to set variables for things like reference brains, templates, and so forth. 

\subsection{Variable overrides}
It is probably a good idea not to edit the makefile too much once it works. But sometimes, it is useful to reissue a command with different parameters. Target-specific variables may be specified in the makefile and overridden on the command line. In the example below, the default flags for FSL bet are specified as \texttt{-f .4 -B -S}.

\begin{make}{Specifying BET flags in make}{make:betflags}
	\maker{\%skstrip.nii.gz}{BETFLAGS = -f .3 -B -S} \\
	\maker{\%skstrip.nii.gz}{\%flair.nii.gz} \\
	\tab bet \$< \$@ \$(BETFLAGS) \\
\end{make}

However, these can be overriden from the command line as follows:

\makecmd{make BETFLAGS="-4 -R"} % Check whether this command is correct

\subsection{Suggested targets}
These suggestions come from experience building pipelines. Having conventions, so that similarly named targets do similar kinds of things across different neuroimaging workflows, is rather helpful and comforting, especially when you spend a lot of time going between modalities and tools.

We propose splitting functions into multiple makefiles that can then be called from a common makefile. It is helpful to avoid overruling target names for common targets. Therefore, if the makefile is called, for example, "convert_dicoms.mk", we will add the text string "convert_dicoms" to the end of each target, as illustrated in the examples below. Top level makefiles (Makefile) can then invoke targets "all", "help", etc., that depend upon the included makefile targets (See General Recipe for Setting up an Analysis Directory With \maken{}).





