\Echapter{Preprocessing Resting State Data}{Benjamin A. Korman}{bkorman@uw.edu}
\label{example:restingstate}
This is an example of how to use a makefile to preprocess functional resting state data. The pipeline incorporates typical preprocessing steps taken when preparing resting state data for analysis. This example includes motion and slice time acquisition correction, brain extraction, signal despiking, spatial smoothing and the calculation and removal of nuisance variables.

The code for this example is in \texttt{testsubject/lib/makefiles}. 

\setcounter{codehighlight}{0} % RESET THIS BEFORE EVERY LST LISTING
\begin{lstlisting}
	%*\lnote*PROJHOME=$$MAKEPIPELINES/testsubject
	SUBJECTS_DIR=$(PROJHOME)/freesurfer
	SCRIPTpath=$(PROJHOME)/bin
	%*\lnote*HWHM=3
	TR=2
	SLICEORDER='ascending'
	NPC=5
	PCTVAR=0
\end{lstlisting}

\lnum{1} In any script or makefile, it is a good idea to set working directory variables early on to ease the script writing process and to avoid later confusion.  In this pipeline we have set a path variable for our subject subdirectory \texttt{PROJHOME} as well as for the subdirectory that is home to the FreeSurfer pipeline's output \texttt{SUBJECTS\_DIR}. In addition, we have set the variable \texttt{SCRIPTpath} to the subdirectory home of additional scripts that will be called during various preprocessing steps. \lnum{2} Besides directory variables, it is helpful for us to set processing-relevant variables which can be used throughout the pipeline. Included here are  variables for the half-width-half-maximum (\texttt{HWHM}) kernel size needed for spatially smoothing the resting state data, the time of repetition (\texttt{TR}) needed for slice time correction, as well as the number of principal components (\texttt{NPC}) and percent variance (\texttt{PCTVAR}) needed when using principal component analysis to calculate regressors for nuisance variables. Including these variables in the Makefile also makes it easy to extract them for inclusion in a generated QA report.

\begin{lstlisting}
	%*\lnote*.PHONY: all rest_dir Freesurfer_test regressors Run_aCompCor postregression clean_rest
	.SECONDARY:
\end{lstlisting}

\lnum{3} The targets listed in the \texttt{.PHONY} section are targets that do not correspond to actual files.   Some of these targets (ex. \texttt{regressors}, \texttt{postregression}) are intended to be used to process the resting state data in grouped steps whereas other \texttt{.PHONY} targets are related to cleanup or testing. One such target is \texttt{clean_rest} which may be called on to eliminate all of the pipeline's generated output when testing and debugging the pipeline.

	%*\lnote*rest: $(call print-help,rest,"Run resting state preprocessing pipeline") rest_dir rest_dir/rest_ssmooth.nii.gz Freesurfer_test xfm_dir/freesurfer_to_rest.mat regressors Run_aCompCor rest_dir/rest_abs_pc1.txt postregression

The \texttt{.PHONY} target \texttt{rest} is used here to easily invoke all preprocessing steps of the pipeline. This is the target we would use to completely preprocess a subject. It is documented using the help system (see \autoref{sec:practicum4}) and depends upon all preprocessing targets, described below.

\begin{lstlisting}
	%*\lnote*rest_dir: rest.nii.gz 
		%*\lnote*echo "Setting up resting-state specific directory" 
		mkdir -p rest_dir ;\
		if [ ! -h rest_dir/rest.nii.gz ];\
		then \
		ln -s $(cwd)/rest.nii.gz rest_dir/rest.nii.gz;\
		fi;\
		if [ ! -h rest_dir/rest.nii.gz ];\
		then \
		ln -s $(cwd)/T1.nii.gz rest_dir/T1.nii.gz;\
		fi
\end{lstlisting}

\lnum{4} This target creates resting state specific subdirectory to keep our project directory clean and organized. We first create \texttt{rest_dir} and then create symbolic links within this directory to the files needed for preprocessing. The required files for resting state preprocessing in this pipeline include the subject's resting state NIfTI image and its corresponding T1 anatomical image.  \lnum{5} Before we do this, we echo (i.e., print to the screen) an informative message to provide progress information while the pipeline runs. Similar informational messages are distributed throughout the remainder of the makefile.

\begin{lstlisting}
	rest_dir/rest_mc.nii.gz: rest_dir/rest.nii.gz
		echo "Preprocessing RESTING scans..." ;\
		echo "Beginning motion correction for rest.nii.gz using 4dRegister" ;\
		%*\lnote*$(SCRIPTpath)/4dRegister.py --inputs $^ --tr $(TR) --slice_order $(SLICEORDER) --time_interp True

\end{lstlisting}

Our first preprocessing step once a resting state-specific subdirectory has been created is to correct the resting state data for signal changes caused by motion and slice time acquisition. To do this we require the unprocessed resting state data, which is the sole dependency in this recipe.  \lnum{6} We will use \texttt{4dRegister.py}, a script provided by the Neuroimaging in Python (NIPY) community, to apply 4D motion and slice time correction simultaneously. The dependency \texttt{rest_dir/rest.nii.gz}, our input, is referred to as \texttt{\$\^} for short in the recipe. The resulting output will renamed with the  \texttt{_mc} extension to indicate that it has been motion corrected.

\begin{lstlisting}
	%*\lnote*rest_dir/rest_bet.nii.gz: rest_dir/rest_mc.nii.gz
		echo "Skull stripping resting data with FSL's BET" ;\
		bet $< $@ -F
\end{lstlisting}

\lnum{7} Following motion and slice time correction, we invoke FSL's BET with the \texttt{-F} flag to skullstrip the 4D resting state data. The output, referred to as \texttt{\$@} for short in the recipe, will be renamed  \texttt{_bet} to indicate that it has undergone brain extraction (aka skull stripping).

\begin{lstlisting}
	rest_dir/rest_despike.nii.gz: rest_dir/rest_bet.nii.gz
		echo "Despiking the functional data with AFNI" ;\
		%*\lnote*3dDespike -ssave spikiness -q $^ ;\
		3dAFNItoNIFTI despike+orig.BRIK ;\
		3dAFNItoNIFTI spikiness+orig.BRIK ;\
		echo "Renaming output, zipping it and deleting unnecessary despike files" ;\
		%*\lnote*mv despike.nii rest_dir/rest_despike.nii ;\
		mv spikiness.nii rest_dir/rest_spikiness.nii ;\
		gzip rest_dir/rest_despike.nii ;\
		gzip rest_dir/rest_spikiness.nii ;\
		rm -f despike+orig* ;\
		rm -f spikiness+orig*
\end{lstlisting}

\lnum{8} After skullstripping the brain, we perform voxel-wise despiking with AFNI to reduce noise caused by framewise displacement. \lnum{9} In addition to our despiked resting state output, a list of "spikiness" values is produced. These are renamed to \texttt{rest_despike.nii.gz} and \texttt{rest_spikiness.nii.gz} respectively. These output files are then compressed to save space while the original output files are removed.

\begin{lstlisting}
	%*\lnote*rest_dir/rest_ssmooth.nii.gz: rest_dir/rest_despike.nii.gz
		echo "Smoothing resting date with FSL's SUSAN" ;\
		susan $^ -1.0 $(HWHM) 3 1 0 $@
\end{lstlisting}

\lnum{10} Once the resting state data has been despiked it is ready to be spatially smoothed. To do this we use FSL's SUSAN with a 3D smoothing kernel 3mm in size. We rename our output with the  \texttt{_ssmooth} extension to indicate that it has been spatially smoothed.

\begin{lstlisting}
	%*\lnote*Freesurfer_test: $(SUBJECTS_DIR)/$(subject)/mri/brainmask.mgz $(SUBJECTS_DIR)/$(subject)/mri/aparc+aseg.mgz

	%*\lnote*xfm_dir/rest_to_freesurfer.mat: rest_dir/rest_despike.nii.gz $(SUBJECTS_DIR)/$(subject)/mri/aparc+aseg.mgz
		mkdir -p xfm_dir ;\
		source /usr/local/freesurfer/stable5_3/SetUpFreeSurfer.sh ;\
		export SUBJECTS_DIR=$(SUBJECTS_DIR) ;\
		fslroi rest_dir/rest_despike.nii.gz rest_dir/rest_despike_vol0 0 1 ;\
		bbregister --s $(subject) --mov rest_dir/rest_despike_vol0.nii.gz --reg xfm_dir/rest_to_freesurfer.dat --init-fsl --bold --o xfm_dir/rest_to_freesurfer.nii.gz --fslmat xfm_dir/rest_to_freesurfer.mat

	%*\lnote*xfm_dir/freesurfer_to_rest.mat: xfm_dir/rest_to_freesurfer.mat
			convert_xfm -omat $@ -inverse $<
\end{lstlisting}

\lnum{11} To proceed with the calculation and removal of nuisance regressors from our spatially smoothed resting state data we first need to check whether the necessary FreeSurfer output files are available. This is because our estimation of background noise in the data will require white matter and cerebrospinal fluid masks which are created from the output of FreeSurfer's \texttt{recon-all} segmentation process. We normally run FreeSurfer separately, because it takes a lot longer to run than the resting state preprocessing. This target depends upon the FreeSurfer results \texttt{brainmask.mgz} and \texttt{aparc+aseg.mgz}. If these do not exist, no processing that depends upon this target can occur. Because the target \texttt{Freesurfer_test} is not an existing file (and will not at any point be created) it is included in the \texttt{.PHONY} section located above.

\lnum{12} Once we are certain that the necessary files exist in our FreeSurfer directory, we create a directory (\texttt{xfm_dir}) in which to keep all of our data transformations. Then, using \texttt{fslroi}, we select the first volume of our despiked resting state data (\texttt{rest_despike_vol0}) as input for FreeSurfer's \texttt{bbregister}. BBregister is used to perform within-subject, cross-modal rigid registration. \lnum{13} After registering the despiked data in FreeSurfer space we must transform this registration back into resting state space. This is because FreeSurfer space is unique and the pipeline will encounter problems if attempting to directly register images from FreeSurfer space to standard (i.e. MNI) space.

\begin{lstlisting}
	%*\lnote*regressors: rest_dir/fs_wMmask.nii.gz rest_dir/fs_csf_mask.nii.gz rest_dir/rest_wm.nii.gz rest_dir/rest_csf.nii.gz

	%*\lnote*rest_dir/fs_wm_mask.nii.gz: $(SUBJECTS_DIR)/$(subject)/mri/aparc+aseg.mgz
		source /usr/local/freesurfer/stable5_3/SetUpFreeSurfer.sh ;\
		export SUBJECTS_DIR=$(SUBJECTS_DIR) ;\
		mri_binarize --i $^ --o $@ --erode 1 --wm

	rest_dir/fs_csf_mask.nii.gz: $(PROJHOME)/freesurfer/$(subject)/mri/aparc+aseg.mgz
		source /usr/local/freesurfer/stable5_3/SetUpFreeSurfer.sh ;\
		export SUBJECTS_DIR=$(SUBJECTS_DIR) ;\
		mri_binarize --i $^ --o $@ --erode 1 --ventricles
		
	%*\lnote*rest_dir/rest_wm.nii.gz: rest_dir/fs_wm_mask.nii.gz rest_dir/rest_despike.nii.gz xfm_dir/freesurfer_to_rest.mat
		flirt  -ref $(word 2,$^) -in $(word 1,$^) -out $@ -applyxfm -init $(word 3,$^) ;\	
		fslmaths $@ -thr .5 -bin $@

	rest_dir/rest_csf.nii.gz: rest_dir/fs_csf_mask.nii.gz rest_dir/rest_despike.nii.gz xfm_dir/freesurfer_to_rest.mat
		flirt  -ref $(word 2,$^) -in $(word 1,$^) -out $@ -applyxfm -init $(word 3,$^) ;\
\end{lstlisting}

\lnum{14} The target \texttt{regressors} is included here for ease of use if one wanted to specifically create or recreate binarized masks from FreeSurfer's white matter and ventricle segmentations. \lnum{15} We binarize and extract white matter and ventricle masks. \lnum{16} We register the despiked resting state data to the white matter and CSF masks using  FSL's FLIRT.  Note that in the recipe the \texttt{\$(word \#, \$\^{})} refers to a dependency in the dependency list. The first dependency may be referenced in the recipe as \texttt{\$(word 1, \$\^{})}, the second \texttt{\$(word 2, \$\^{})}, and so forth.

\begin{lstlisting}
	%*\lnote*Run_aCompCor: rest_dir/rest_wm.txt rest_dir/rest_csf.txt

	rest_dir/rest_wm.txt: rest_dir/rest_despike.nii.gz rest_dir/rest_wm.nii.gz
		fslmaths rest_dir/rest_despike.nii.gz -mas rest_dir/rest_wm.nii.gz rest_dir/rest_wm_ts.nii.gz ;\
		%*\lnote*Rscript  $(SCRIPTpath)/aCompCor.R rest_dir/rest_wm_ts.nii.gz $(NPC) $(PCTVAR) ;\
		convert rest_dir/rest_wm_ts_VarianceExplained.png rest_dir/rest_wm_ts_VarianceExplained.gif ;\
		rm rest_dir/rest_wm_ts_VarianceExplained.png ;\
		mv rest_dir/rest_wm_ts_pc.txt $@

	rest_dir/rest_csf.txt: rest_dir/rest_despike.nii.gz rest_dir/rest_csf.nii.gz
		fslmaths rest_dir/rest_despike.nii.gz -mas rest_dir/rest_csf.nii.gz rest_dir/rest_csf_ts.nii.gz ;\
		Rscript  $(SCRIPTpath)/aCompCor.R rest_dir/rest_csf_ts.nii.gz $(NPC) $(PCTVAR) ;\
		convert rest_dir/rest_csf_ts_VarianceExplained.png rest_dir/rest_csf_ts_VarianceExplained.gif ;\
		rm rest_dir/rest_csf_ts_VarianceExplained.png ;\
		mv rest_dir/rest_csf_ts_pc.txt $@
		
	%*\lnote*rest_dir/rest_abs_pc1.txt: rest_dir/rest_mc.nii.gz
		echo "Creating list of motion regressors using MotionRegressorGenerator.py" ;\
		$(SCRIPTpath)/MotionRegressorGenerator.py -i rest_dir/rest.par -o rest_dir/rest
		
	%*\lnote*rest_dir/rest_nuisance_regressors.txt: rest_dir/rest_csf.txt rest_dir/rest_wm.txt rest_dir/rest_abs_pc1.txt
		echo "Combine lists of motion regressors into one text file" ;\
		paste $(word 1,$^) $(word 2,$^) $(word 3,$^) rest_dir/rest_rel_pc1.txt > $@
\end{lstlisting}

Once we have registered the despiked resting state data to the white matter and CSF masks, we need to compute nuisance regressors. \lnum{17} The target \texttt{Run_aCompCor} depends upon these regressors and is a convenience target. \lnum{18} The R script \texttt{aCompCor} calculate nuisance regressors from the masked resting state data. This script can extract a set number of principal components \texttt{NPC} or by setting a specific percent of variance \texttt{PCTVAR} that should be explained by the principal components included in the analysis. In this example we use 5 principal components. 
 \lnum{19}  A python script named \texttt{MotionRegressorGenerator}, located in the \texttt{bin} directory, is also called in this pipeline to calculate nuisance regressors from motion parameters. \lnum{20} The nuisance regressors generated during this step are then combined with the nuisance regressors calculated by \texttt{aCompCor} into a single text file. 

\begin{lstlisting}
	%*\lnote*postregression: rest_dir/rest_designrange.txt rest_dir/rest_postregression.nii.gz
		echo "Regressing motion artifacts out of resting-state data"

	%*\lnote*rest_dir/rest_designrange.txt: rest_dir/rest_nuisance_regressors.txt
		Rscript $(SCRIPTpath)/rangeArray.R $< $@

	%*\lnote*rest_dir/rest_postregression.nii.gz: rest_dir/rest_ssmooth.nii.gz rest_dir/rest_nuisance_regressors.txt rest_dir/rest_designrange.txt
		npc=`awk '{print NF}' $(word 2, $^) | sort -nu | tail -n 1` ;\
		npts=`wc -l $(word 2, $^)` ;\
		echo "/NumWaves $$npc" >  rest_dir/rest_regressors.feat.mat ;\
		echo "/NumPoints $$npts" >> rest_dir/rest_regressors.feat.mat ;\
		echo "/PPheights " `cat $(word 3, $^)` >> rest_dir/rest_regressors.feat.mat ;\
		echo "/Matrix" >> rest_dir/rest_regressors.feat.mat ;\
		cat $(word 2, $^) >> rest_dir/rest_regressors.feat.mat ;\
		reglist="1"; for i in `seq 2 $$npc`; do reglist=`echo $$reglist`,$$i; done ;\
		echo $$reglist ;\
		fsl_regfilt -i  rest_dir/rest_ssmooth.nii.gz -d rest_dir/rest_regressors.feat.mat -f $$reglist -o $@
\end{lstlisting}

Once the nuisance regressors have been calculated and combined into a single file, the next step is to remove them from the data. \lnum{21} This portion of the pipeline may be called specifically using the target \texttt{postregression}. \lnum{22} To regress out nuisance variables, we create a little FEAT design matrix and run \texttt{fsl_regfilt}. We calculate the range of the included nuisance regressors using the R script \texttt{rangeArray.R}. \lnum{23} Finally, we denoise the data by regressing out the nuisance regressors using simple ordinary least squares regression with FSL.

\begin{lstlisting}
	clean_rest:
		echo "Removing all output files except for freesurfer transforms" ;\
		rm -rf rest_dir
\end{lstlisting}

Lastly, we create a target to remove all files created by the pipeline. This is particularly useful when testing and debugging the pipeline. When called, this target will simply remove the \texttt{rest_dir} directory and all files located within it; in other words, everything that we have created with this Makefile.


